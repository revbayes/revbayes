x ~ dnNormal(0,1) |> tnShift(1)
x ~ dnNormal(0,1) |> tnScale(1)
p ~ dnNormal(0,1) |> tnInvlogit()
x ~ dnNormal(0,1) |> tnExp()

x ~ 1 + dnNormal(0,1)
x ~ dnNormal(0,1) + 1
x ~ 1 + dnExponential(1)
x ~ dnExponential(1) + 1

x ~ dnBeta(1,2) |> tnShift(1)
x ~ dnBeta(1,2) |> tnScale(1)
x ~ dnBeta(1,2) |> tnLog()
x ~ dnBeta(1,2) |> tnExp()
x ~ dnBeta(1,2) |> tnLogit()

# Shifting or scaling by positive things retains positivity.
x ~ dnExponential(1) |> tnShift(1) |> tnLog()
x ~ (dnExponential(1) + 1) |> tnLog()
x ~ (1 + dnExponential(1)) |> tnLog()

x ~ dnExponential(1) |> tnScale(2) |> tnLog()

# A probability multiplied by a probability remains a probability.
x ~ dnBeta(1,2) |> tnScale(0.5) |> tnLogit()

# But shifting or scaling by negative things is still allowed
x ~ dnExponential(1) |> tnShift(-1)
x ~ dnExponential(1) |> tnScale(-2)

mu = [1.0, 2.0, 3.0, 4.0]
Sigma ~ dnWishart(df=4, kappa=2, dim=4)
x ~ dnMultivariateNormal(mu,Sigma) |> tnExp()

mu = [1.0, 2.0, 3.0, 4.0]
Sigma ~ dnWishart(df=4, kappa=2, dim=4)
x ~ dnMultivariateNormal(mu,Sigma) |> tnExp() |> tnLog()

x ~ dnDirichlet([1,1,1,1]) |> tnLog()
x ~ dnDirichlet([1,1,1,1]) |> tnLogit()
x ~ dnDirichlet([1,1,1,1]) |> tnLogit() |> tnInvlogit()

x ~ dnIID(4,dnNormal(0,1)) |> tnInvlogit()
x ~ dnIID(4,dnNormal(0,1)) |> tnInvlogit() |> tnLogit()

q()
